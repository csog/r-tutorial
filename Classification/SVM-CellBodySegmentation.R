# Training SVM Models
library(caret)
library(dplyr)         # Used by caret
library(kernlab)       # support vector machine
library(pROC)	         # plot the ROC curves

### Get the Data
# Load the data and construct indices to divide it into training and test data sets.
# Description
# Hill, LaPan, Li and Haney (2007) develop models to predict which cells in a high 
# content screen were well segmented. The data consists of 119 imaging measurements 
# on 2019. The original analysis used 1009 for training and 1010 as a test set (see the column called Case).
# 
# The outcome class is contained in a factor variable called Class with levels 
# "PS" for poorly segmented and "WS" for well segmented.
data(segmentationData)  	# Load the segmentation data set

trainIndex <- createDataPartition(segmentationData$Case,p=.5,list=FALSE)
trainData <- segmentationData[trainIndex,]
testData  <- segmentationData[-trainIndex,]
trainX <-trainData[,4:61]        # Pull out the variables for training
sapply(trainX,summary)           # Look at a summary of the training data

## SUPPORT VECTOR MACHINE MODEL
# First pass
set.seed(1711)
# Setup for cross validation
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
                     repeats=5,		          # do 5 repititions of cv
                     summaryFunction=twoClassSummary,	# Use AUC to pick the best model
                     classProbs=TRUE)


#Train and Tune the SVM
svm.tune <- train(x=trainX,
                  y= trainData$Class,
                  method = "svmRadial",           # Radial kernel
                  tuneLength = 9,					        # 9 values of the cost function
                  preProc = c("center","scale"),  # Center and scale data
                  metric="ROC",
                  trControl=ctrl)

svm.tune


# Second pass
# Look at the results of svm.tune and refine the parameter space
# In the second pass  we use train()'s tuneGrid parameter to do some sensitivity 
# analysis around the values C = 1 and sigma = 0.015 that produced the model with 
# the best ROC value. R's expand.grid() function is used to build a dataframe 
# contain all the combinations of C and sigma we want to look at.

set.seed(1711)
# Use the expand.grid to specify the search space
grid <- expand.grid(sigma = c(.01, .015, 0.2),
                    C = c(0.75, 0.9, 1, 1.1, 1.25)
)

#Train and Tune the SVM
svm.tune <- train(x=trainX,
                  y= trainData$Class,
                  method = "svmRadial",
                  preProc = c("center","scale"),
                  metric="ROC",
                  tuneGrid = grid,
                  trControl=ctrl)

svm.tune


#Linear Kernel
set.seed(1711)                     

#Train and Tune the SVM
svm.tune2 <- train(x=trainX,
                   y= trainData$Class,
                   method = "svmLinear",
                   preProc = c("center","scale"),
                   metric="ROC",
                   trControl=ctrl)	


svm.tune2


# we can use caret's resample() function to compare the results generated by 
# the radial kernel and linear kernel models. 
# IMportatn: pseudo number generator has to be set to the same value!

rValues <- resamples(list(svm=svm.tune,svm.tune2))
head(rValues$values)

summary(rValues)

bwplot(rValues,metric="ROC",ylab =c("linear kernel", "radial kernel"))		
